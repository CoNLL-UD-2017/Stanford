#***************************************************************
# Where things are located
[Configurable]
train_files = colon/separated/list/of/files:supports/glob/*
parse_files = colon/separated/list/of/files:supports/glob/*

[Pretrained Vocab]
filename = location/of/pretrained/embeddings
skip_header = True #skips the first line of the file, which sometimes contains metadata about the embedding matrix

#***************************************************************
# Embedding hyperparameters
[Char Vocab]
embed_model = RNNEmbed #{RNNEmbed, CNNEmbed, MLPEmbed} 

[Multivocab] # The aggregated word vocab, pretrained vocab, and char vocab
embed_keep_prob = .67 # probability of dropping a word embedding

[Tag Vocab]
embed_keep_prob = .67 # probability of dropping a tag embedding

[RNN Embed]
recur_cell = LSTMCell #{RNNCell, GRUCell, LSTMCell, CifLSTMCell}
n_layers = 3 #number of LSTM layers
recur_size = 400 #number of recurrent units
recur_keep_prob = .67 #probability of dropping a connection between timesteps at a single layer
ff_keep_prob = .67 #probability of dropping a connection between layers at a single timestep

#***************************************************************
# NLP model hyperparameters
[Tagger]
output_vocabs = tags:xtags #if you only want it to produce the first column of tags, set this to just 'tags'
recur_cell = LSTMCell #{RNNCell, GRUCell, LSTMCell, CifLSTMCell}
n_layers = 2 #number of LSTM layers
recur_size = 400 #number of recurrent units in each direction of the BiLSTM
mlp_size = 600 #number of units in the tag classifier
mlp_keep_prob = .67 #probability of dropping a node in the MLP or the classifier
recur_keep_prob = .5 #probability of dropping a connection between timesteps at a single layer
ff_keep_prob = .67 #probability of dropping a connection between layers at a single timestep

[Parser]
input_vocabs = words:tags:xtags #if you only want it to use the first column of tags, set this to 'words:tags'
recur_cell = LSTMCell #{RNNCell, GRUCell, LSTMCell, CifLSTMCell}
n_layers = 3 #number of layers
recur_size = 400 #number of recurrent units
arc_mlp_size = 600 #number of units in the edge classifier
rel_mlp_size = 100 #number of units in the label classifier (you probably want this to be small!)
mlp_keep_prob = .67 #probability of dropping a node in the MLP or the classifier
recur_keep_prob = .67 #probability of dropping a connection between timesteps at a single layer
ff_keep_prob = .67 #probability of dropping a connection between layers at a single timestep

#***************************************************************
# Training hyperparameters
[Network]
nlp_model = Parser #{Parser, Tagger}
quit_after_n_iters_without_improvement = 5000
max_train_iters = 50000
